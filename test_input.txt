
### 2.2 LangChain Go 中如何集成不同的 LLM

LangChain Go 的一个巨大优势是它提供了**统一的接口**，让你能够轻松集成不同的 LLM。这就像一个适配器，无论你用的是 OpenAI 的 GPT 模型，还是 Hugging Face 上的开源模型，甚至是在本地运行的 Ollama 模型，LangChain Go 都能让你以相似的方式与它们交互。

要集成一个 LLM，通常只需要几行代码。例如，如果你想使用 **OpenAI** 的模型，你会在代码中导入 `github.com/tmc/langchaingo/llms/openai` 包，然后像这样创建 LLM 实例：

```go
// 确保 OPENAI_API_KEY 环境变量已设置
apiKey := os.Getenv("OPENAI_API_KEY")
if apiKey == "" {
    log.Fatal("OPENAI_API_KEY 环境变量未设置")
}

// 创建 OpenAI LLM 实例
llm, err := openai.New(openai.WithToken(apiKey))
if err != nil {
    log.Fatal(err)
}
```

这里我们通过 `openai.New()` 函数创建了一个 LLM 对象，并通过 `openai.WithToken()` 选项传入了你的 API 密钥。

如果你想使用其他模型，比如通过 **Ollama** 在本地运行的模型，代码结构也会非常相似，只是导入的包和创建实例的函数会不同：

```go
// 导入 ollama 包
import "github.com/tmc/langchaingo/llms/ollama"

// 创建 Ollama LLM 实例
llm, err := ollama.New(ollama.WithModel("llama2")) // 指定你想使用的本地模型，例如 llama2
if err != nil {
    log.Fatal(err)
}
```